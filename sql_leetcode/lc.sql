"
Why Normal Form (NF)?
è³‡æ–™é‡è¤‡ï¼šåŒæ¨£çš„è³‡è¨Šåœ¨ä¸åŒåœ°æ–¹å‡ºç¾å¤šæ¬¡ã€‚
æ›´æ–°å›°é›£ï¼šæƒ³æ”¹ä¸€å€‹åœ°æ–¹ï¼Œçµæœè¦æ”¹å¥½å¤šå€‹åœ°æ–¹ã€‚
åˆªé™¤æˆ–æ–°å¢å•é¡Œï¼šä¸€ä¸å°å¿ƒå°±åˆªåˆ°æˆ–æ–°å¢äº†ä¸è©²æ”¾ä¸€èµ·çš„è³‡æ–™ã€‚

1NFï¼ˆç¬¬ä¸€æ­£è¦åŒ–ï¼‰ï¼šæ¬„ä½åªèƒ½å­˜å–®ä¸€å€¼ï¼Œä¸èƒ½æœ‰ã€Œè˜‹æœ, é¦™è•‰ã€é€™ç¨®å¤šå€¼æƒ…æ³ã€‚(atomic)
2NFï¼ˆç¬¬äºŒæ­£è¦åŒ–ï¼‰ï¼šéä¸»éµæ¬„ä½è¦å®Œå…¨ä¾è³´ä¸»éµï¼Œä¸èƒ½åªä¾è³´ã€Œéƒ¨åˆ†ã€ä¸»éµï¼ˆä¾‹å¦‚ã€Œå•†å“åç¨±ã€ä¸æ‡‰è©²ä¾è³´ã€Œè¨‚å–®IDã€ï¼‰ã€‚
    -->å¦‚æœè©²è¡¨æœ‰ã€Œè¤‡åˆä¸»éµã€ï¼ˆä¹Ÿå°±æ˜¯ä¸€å¼µè¡¨çš„ä¸»éµæ˜¯ç”±å¥½å¹¾å€‹æ¬„ä½ä¸€èµ·çµ„æˆï¼‰ï¼Œé‚£éº¼æ¯ä¸€å€‹ã€Œéä¸»éµæ¬„ä½ã€éƒ½å¿…é ˆä¾è³´æ•´å€‹ä¸»éµï¼Œè€Œä¸æ˜¯åªä¾è³´å…¶ä¸­ä¸€éƒ¨åˆ†ã€‚
3NFï¼ˆç¬¬ä¸‰æ­£è¦åŒ–ï¼‰ï¼šéä¸»éµæ¬„ä½ä¸èƒ½é€éå…¶ä»–éä¸»éµæ¬„ä½ä¾†ç²å¾—ï¼ˆä¾‹å¦‚ã€Œå®¢æˆ¶åç¨±ã€æ‡‰è©²æ”¾åˆ°å®¢æˆ¶è¡¨ï¼Œè€Œä¸æ˜¯è¨‚å–®è¡¨ï¼‰ã€‚

ç¬¬äºŒæ­£è¦åŒ– (2NF) - æ¶ˆé™¤ã€Œéƒ¨åˆ†ä¾è³´ã€ï¼Œé¿å…é‡è¤‡
åœ¨ 1NF ä¹‹å¾Œï¼Œç¾åœ¨çœ‹çœ‹é€™å¼µè¡¨ï¼š

è¨‚å–®ID	å®¢æˆ¶åç¨± å•†å“ID	å•†å“åç¨±
001	    å°æ˜	A01	   è˜‹æœ
001	    å°æ˜	A02    é¦™è•‰
002	    å°è¯	A03	   è¥¿ç“œ
å•é¡Œï¼š

ä¸»éµæ˜¯ã€Œè¨‚å–®ID + å•†å“IDã€çš„çµ„åˆï¼ˆå› ç‚ºä¸€å¼µè¨‚å–®å¯èƒ½åŒ…å«å¤šå€‹å•†å“ï¼‰ã€‚
ä½†æ˜¯ã€Œå•†å“åç¨±ã€åªä¾è³´æ–¼ã€Œå•†å“IDã€ï¼Œèˆ‡ã€Œè¨‚å–®IDã€ç„¡é—œï¼Œé€™æ˜¯éƒ¨åˆ†ä¾è³´ã€‚
ä¾‹å¦‚ï¼šã€ŒA01ï¼ˆè˜‹æœï¼‰ã€åœ¨å¤šå€‹è¨‚å–®è£¡éƒ½æ˜¯è˜‹æœï¼Œæ²’å¿…è¦é‡è¤‡å­˜ã€Œè˜‹æœã€ã€‚
è§£æ±ºæ–¹æ³•ï¼šæ‹†æˆå…©å¼µè¡¨ï¼š

è¨‚å–®-å•†å“è¡¨ï¼š

è¨‚å–®ID	å®¢æˆ¶åç¨±	å•†å“ID
001	å°æ˜	A01
001	å°æ˜	A02
002	å°è¯	A03
å•†å“è¡¨ï¼š

å•†å“ID	å•†å“åç¨±
A01	è˜‹æœ
A02	é¦™è•‰
A03	è¥¿ç“œ
âœ… é€™æ¨£å°±ç¬¦åˆ 2NFï¼Œå› ç‚ºã€Œå•†å“åç¨±ã€ç¾åœ¨åªä¾è³´æ–¼ã€Œå•†å“IDã€ï¼Œä¸æœƒè·Ÿã€Œè¨‚å–®IDã€æ··åœ¨ä¸€èµ·ã€‚

ç¬¬ä¸‰æ­£è¦åŒ– (3NF) - æ¶ˆé™¤ã€Œå‚³éä¾è³´ã€ï¼Œé¿å…é–“æ¥é—œä¿‚
ç¾åœ¨çœ‹çœ‹é€™å¼µè¡¨ï¼š

è¨‚å–®ID	å®¢æˆ¶ID	å®¢æˆ¶åç¨±	å®¢æˆ¶åœ°å€
001	C01	å°æ˜	å°åŒ—
002	C02	å°è¯	é«˜é›„
å•é¡Œï¼š

ã€Œå®¢æˆ¶åç¨±ã€å’Œã€Œå®¢æˆ¶åœ°å€ã€æ˜¯ä¾è³´æ–¼ã€Œå®¢æˆ¶IDã€çš„ï¼Œè€Œä¸æ˜¯ç›´æ¥ä¾è³´ã€Œè¨‚å–®IDã€ã€‚
ä¹Ÿå°±æ˜¯ï¼šã€Œè¨‚å–®ID â†’ å®¢æˆ¶ID â†’ å®¢æˆ¶åç¨±ã€å®¢æˆ¶åœ°å€ã€ï¼Œé€™æ˜¯ã€Œå‚³éä¾è³´ã€ã€‚
è§£æ±ºæ–¹æ³•ï¼šæ‹†æˆå…©å¼µè¡¨ï¼š

è¨‚å–®è¡¨ï¼š

è¨‚å–®ID	å®¢æˆ¶ID
001	C01
002	C02
å®¢æˆ¶è¡¨ï¼š

å®¢æˆ¶ID	å®¢æˆ¶åç¨±	å®¢æˆ¶åœ°å€
C01	å°æ˜	å°åŒ—
C02	å°è¯	é«˜é›„
âœ… é€™æ¨£å°±ç¬¦åˆ 3NFï¼Œå› ç‚ºã€Œå®¢æˆ¶åç¨±ã€å’Œã€Œå®¢æˆ¶åœ°å€ã€ç›´æ¥ä¾è³´ã€Œå®¢æˆ¶IDã€ï¼Œè€Œä¸æ˜¯é€éã€Œè¨‚å–®IDã€ä¾†é–“æ¥é—œè¯ã€‚


2NFï¼šé¿å…åŒæ¨£çš„è³‡æ–™ä¸€ç›´é‡è¤‡å¯«ï¼ˆåƒæ˜¯é¡§å®¢åå­—ï¼‰
3NFï¼šé¿å…æ”¹ä¸€å€‹è³‡æ–™è¦æ”¹å¾ˆå¤šè™•ï¼ˆåƒæ˜¯ä¾›æ‡‰å•†é›»è©±ï¼‰
-------------------------------------------------------------------------------------------------

BCNFï¼šä»»ä½•èƒ½æ±ºå®šå…¶ä»–æ¬„ä½çš„æ¢ä»¶ (æ±ºå®šå…ƒ, Determinant) ï¼Œéƒ½å¿…é ˆæ˜¯æŸå€‹ã€Œå€™é¸éµã€(Candidate Key)ã€‚
æ›å¥è©±èªªï¼Œå¦‚æœä¸€å€‹æ¬„ä½ (æˆ–æ¬„ä½çµ„åˆ) å¯ä»¥æ±ºå®šè¡¨ä¸­çš„å…¶ä»–æ¬„ä½ï¼Œé‚£é€™å€‹æ¬„ä½(æˆ–æ¬„ä½çµ„åˆ) æœ¬èº«å°±è¦èƒ½å”¯ä¸€è­˜åˆ¥æ•´ç­†è³‡æ–™ã€‚
BCNF å…¶å¯¦æ˜¯ 3NF çš„ã€Œæ›´åš´æ ¼ç‰ˆæœ¬ã€ï¼Œæœ‰äº›åœ¨ 3NF ä¸è¢«èªç‚ºæ˜¯å•é¡Œçš„ä¾è³´é—œä¿‚ï¼Œåœ¨ BCNF è£¡å°±æœƒè¢«æŒ‘å‡ºä¾†ã€‚
ç¯„ä¾‹ï¼šèª²ç¨‹ã€è€å¸«èˆ‡æ•™å®¤
æƒ…å¢ƒè¨­å®š
ä¸€ä½è€å¸«å¯ä»¥æ•™å¤šé–€èª²ç¨‹ã€‚
ä½†æ¯ä½è€å¸«åœ¨æ ¡å…§æœ‰ä¸€é–“ã€Œå°ˆå±¬ã€çš„å›ºå®šæ•™å®¤ã€‚
ä¸€é–€èª²ç¨‹å¯ä»¥ç”±å¤šä½è€å¸«å…±åŒæ•™æˆï¼ˆæˆ–è¼ªæµä¸Šèª²ï¼‰ã€‚
è¡¨æ ¼è¨­è¨ˆï¼ˆé•å BCNF çš„ç‹€æ³ï¼‰
æˆ‘å€‘è¨­è¨ˆä¸€å€‹è¡¨ ClassScheduleï¼Œç”¨ä¾†è¨˜éŒ„ã€Œèª²ç¨‹ã€è€å¸«ã€æ•™å®¤ã€çš„å°æ‡‰é—œä¿‚ï¼š

èª²ç¨‹ID	è€å¸«ID	æ•™å®¤ID
C001	T01	R101
C002	T01	R101
C001	T02	R202
C003	T03	R303
...	...	...
ä¸»éµ (Primary Key)ï¼š

å‡è¨­é€™å¼µè¡¨è¨­å®š (èª²ç¨‹ID, è€å¸«ID) ä½œç‚ºè¤‡åˆä¸»éµ
è¡¨ç¤ºåŒä¸€é–€èª²ç¨‹å¯ä»¥å°æ‡‰åˆ°å¤šä½è€å¸«ï¼Œä¹Ÿå¯ä»¥å¤šç­†ç´€éŒ„
åŠŸèƒ½ç›¸ä¾ (Functional Dependencies)ï¼š
(èª²ç¨‹ID,è€å¸«ID) â†’ æ•™å®¤ID
ï¼ˆå› ç‚ºä¸»éµå¯ä»¥æ±ºå®šæ•™å®¤æ˜¯å“ªä¸€é–“ï¼Œé€™æ˜¯è¡¨é¢ä¸Šçœ‹èµ·ä¾†ç¬¦åˆ 3NF çš„åŸå› ï¼‰
ä½†é‚„æœ‰ï¼š è€å¸«ID â†’ æ•™å®¤ID
ï¼ˆåœ¨é€™å€‹æƒ…å¢ƒä¸‹ï¼Œæ¯ä½è€å¸«éƒ½å›ºå®šä¸€é–“æ•™å®¤ï¼Œä¹Ÿå°±æ˜¯åªè¦çŸ¥é“ã€Œè€å¸«IDã€ï¼Œå°±èƒ½çŸ¥é“ã€Œæ•™å®¤IDã€æ˜¯å“ªä¸€é–“ï¼‰
ç‚ºä»€éº¼ 3NF å¯èƒ½ã€Œè¡¨é¢ä¸Šã€è¦ºå¾—æ²’å•é¡Œï¼Ÿ
åªçœ‹å‰å…©é»ï¼šã€Œéä¸»éµï¼ˆæ•™å®¤IDï¼‰ä¾è³´ä¸»éµï¼ˆèª²ç¨‹ID+è€å¸«IDï¼‰ã€ï¼Œæ„Ÿè¦ºæ²’æœ‰ä¾è³´åœ¨å…¶ä»–éä¸»éµæ¬„ä½ä¹‹ä¸Šï¼Œæ‰€ä»¥å¾ˆå¤šäººæœƒè¦ºå¾—ã€Œå¥½åƒå·²ç¶“ 3NF äº†ã€ã€‚
ç‚ºä»€éº¼é•å BCNFï¼Ÿ
åœ¨ BCNF ä¸­ï¼Œä»»ä½•èƒ½æ±ºå®šå…¶ä»–æ¬„ä½çš„æ¬„ä½ï¼ˆæ±ºå®šå…ƒï¼‰ï¼Œå¿…é ˆæ˜¯å€™é¸éµã€‚
åœ¨é€™å€‹ä¾‹å­è£¡ï¼Œã€Œè€å¸«IDã€å°±èƒ½æ±ºå®šã€Œæ•™å®¤IDã€ã€‚ä½†æ˜¯ã€Œè€å¸«IDã€ä¸¦ä¸æ˜¯è¡¨çš„å€™é¸éµï¼ˆå› ç‚ºä¸€ä½è€å¸«å¯æ•™å¤šé–€èª²ç¨‹ï¼Œå–®æ†‘ è€å¸«ID ç„¡æ³•å”¯ä¸€åˆ†è¾¨è¡¨è£¡çš„æ¯ä¸€ç­†ç´€éŒ„ï¼‰ã€‚
ä¹Ÿå°±æ˜¯ï¼š
è€å¸«ID â†’ æ•™å®¤ID
ä½† è€å¸«ID ä¸æ˜¯å€™é¸éµ
é€™æ¨£å°±é•åäº† BCNF çš„è¦æ±‚ã€‚

--------------------------------------------------------------------------------------------
1. ä¸»éµ (Primary Key): not null, unique(), minimal, one primary key
2. å€™é¸éµï¼ˆCandidate Keyï¼‰æŒ‡çš„æ˜¯åœ¨è³‡æ–™è¡¨ä¸­ï¼Œä¸€çµ„ï¼ˆæˆ–ä¸€å€‹ï¼‰æ¬„ä½èƒ½å”¯ä¸€è¾¨è­˜ä¸€ç­†ç´€éŒ„ï¼Œè€Œä¸”é€™çµ„æ¬„ä½ä¸èƒ½å†ç¸®å°ï¼ˆä¹Ÿå°±æ˜¯èªªï¼Œå¦‚æœæ‹¿æ‰ä»»ä½•ä¸€å€‹æ¬„ä½ï¼Œå°±ä¸å†èƒ½å”¯ä¸€è¾¨è­˜è³‡æ–™ï¼‰ã€‚
    ä»¥ä¸‹å¹¾å€‹é‡é»è®“ä½ æ›´å®¹æ˜“ç†è§£ï¼š
    èƒ½å”¯ä¸€è¾¨è­˜ï¼š
    åªè¦ä½ çŸ¥é“ã€Œå€™é¸éµã€æ¬„ä½çš„å€¼ï¼Œå°±å¯ä»¥åœ¨è¡¨è£¡ç²¾æº–æ‰¾åˆ°å°æ‡‰çš„é‚£ä¸€ç­†æˆ–é‚£å¹¾ç­†è³‡æ–™ï¼ˆé€šå¸¸æ˜¯ä¸€ç­†ï¼‰ã€‚
    ä¾‹å¦‚ï¼š
    å­¸ç”ŸID, èª²ç¨‹ID
    å­¸ç”ŸID,èª²ç¨‹ID å¯èƒ½ä¸€èµ·å¯ä»¥è¾¨è­˜ä¸€ç­†ã€Œé¸èª²ã€è³‡æ–™ã€‚è‹¥åªç”¨ã€Œå­¸ç”ŸIDã€æˆ–åªç”¨ã€Œèª²ç¨‹IDã€ï¼Œå¯èƒ½æœƒå°æ‡‰åˆ°å¤šç­†è³‡æ–™ï¼Œå°±ä¸å¤ å”¯ä¸€ã€‚
    æœ€å°æ€§ (Minimality)ï¼š
    é€™çµ„æ¬„ä½åˆåœ¨ä¸€èµ·ã€Œç¨ä¸€ç„¡äºŒã€çš„åŒæ™‚ï¼Œä¸èƒ½å†æ‹¿æ‰ä»»ä½•æ¬„ä½ï¼Œå¦å‰‡å°±å¤±å»å”¯ä¸€è¾¨è­˜çš„èƒ½åŠ›ã€‚
    å¦‚æœå¯ä»¥æ‹¿æ‰å…¶ä¸­ä¸€æ¬„ï¼Œé‚„èƒ½å”¯ä¸€è¾¨è­˜ï¼Œå°±ä»£è¡¨åŸä¾†é‚£çµ„æ¬„ä½ä¸æ˜¯æœ€å°çš„çµ„åˆï¼Œé‚£å®ƒå°±ä¸æ˜¯ã€Œå€™é¸éµã€ã€‚

    åœ¨ä¸€å¼µè¡¨ä¸­ï¼Œå¯èƒ½æœ‰ä¸åªä¸€å€‹å€™é¸éµï¼ˆå¤šçµ„æ¬„ä½éƒ½èƒ½å”¯ä¸€è¾¨è­˜è³‡æ–™ï¼‰ã€‚
    å…¶ä¸­ä¸€å€‹è¢«é¸å®šç•¶ä½œã€Œä¸»éµã€ï¼ˆPrimary Keyï¼‰ï¼Œå…¶ä»–çš„éƒ½é‚„æ˜¯ã€Œå€™é¸éµã€ï¼Œåªæ˜¯æ²’è¢«é¸ä¾†ç•¶ä¸»éµè€Œå·²ã€‚

3. Super Keyï¼ˆè¶…éµï¼‰
    å®šç¾©ï¼š

    åœ¨ä¸€å¼µè³‡æ–™è¡¨è£¡ï¼Œä¸€å€‹æˆ–å¤šå€‹æ¬„ä½çš„çµ„åˆï¼Œåªè¦èƒ½ã€Œå”¯ä¸€è­˜åˆ¥ (Identify)ã€æ¯ä¸€ç­†è³‡æ–™ï¼Œå°±æ˜¯ä¸€å€‹ Super Keyã€‚
    ä½† Super Key ä¸è¦æ±‚æœ€å°åŒ–ï¼Œä¹Ÿå°±æ˜¯èªªï¼Œå®ƒå¯ä»¥åŒ…å«å¤šé¤˜çš„æ¬„ä½ï¼Œåªè¦é€™å€‹çµ„åˆä»ç„¶èƒ½åˆ†è¾¨æ¯ç­†è³‡æ–™å°±ç®—æ˜¯ Super Keyã€‚
    ä¾‹å­ï¼š

    å‡è¨­åœ¨ã€Œå­¸ç”Ÿã€è¡¨è£¡ï¼Œæœ‰æ¬„ä½ï¼š(å­¸è™Ÿ, å§“å, èº«åˆ†è­‰å­—è™Ÿ, æ‰‹æ©Ÿè™Ÿç¢¼)ã€‚
    ã€Œ(å­¸è™Ÿ, å§“å)ã€å¯ä»¥å”¯ä¸€è­˜åˆ¥å­¸ç”Ÿå—ï¼Ÿ
    å¦‚æœå…‰æ˜¯ã€Œå­¸è™Ÿã€å°±å·²ç¶“å”¯ä¸€äº†ï¼ŒåŠ ä¸Šã€Œå§“åã€ä¹Ÿé‚„æ˜¯èƒ½å”¯ä¸€è­˜åˆ¥ï¼Œä½†é€™æ¨£å°±å¤šé¤˜äº†ï¼ˆå› ç‚ºå…¶å¯¦åªé ã€Œå­¸è™Ÿã€å°±å·²ç¶“å¯ä»¥åˆ†è¾¨æ¯ç­†è³‡æ–™ï¼‰ã€‚
    æ‰€ä»¥ã€Œ(å­¸è™Ÿ, å§“å)ã€æ˜¯ä¸€å€‹ Super Keyï¼Œä½†ä¸æ˜¯æœ€å°çµ„åˆã€‚

4. Alternate Keyï¼ˆæ›¿ä»£éµï¼‰ (å‰©ä¸‹çš„æ²’æœ‰è¢«é¸ç‚º Primary Key çš„ Candidate Keyã€‚)
   æ˜¯æŒ‡ã€Œé™¤äº†ä¸»éµï¼ˆPrimary Keyï¼‰ä»¥å¤–ï¼Œå…¶å®ƒå¯ç”¨ä¾†å”¯ä¸€è­˜åˆ¥è³‡æ–™çš„ Candidate Keyã€ã€‚
   å®šç¾©ï¼š

    æ˜¯æŒ‡ã€Œé™¤äº†ä¸»éµï¼ˆPrimary Keyï¼‰ä»¥å¤–ï¼Œå…¶å®ƒå¯ç”¨ä¾†å”¯ä¸€è­˜åˆ¥è³‡æ–™çš„ Candidate Keyã€ã€‚
    é€šå¸¸æˆ‘å€‘æœƒé¸æ“‡ã€Œå­¸è™Ÿã€ç•¶ä¸»éµï¼Œæˆ–é¸æ“‡ã€Œå“¡å·¥ç·¨è™Ÿã€ç•¶ä¸»éµï¼Œé‚£éº¼ç³»çµ±ä¸­å¦‚æœé‚„æœ‰ã€Œèº«åˆ†è­‰å­—è™Ÿã€ã€ã€Œè­·ç…§è™Ÿç¢¼ã€ç­‰ä¹Ÿèƒ½å”¯ä¸€è¾¨è­˜çš„æ¬„ä½ï¼Œå°±å±¬æ–¼ Alternate Keyã€‚
    ä¾‹å­ï¼š

    ä¸€å¼µã€Œå­¸ç”Ÿã€è¡¨è£¡ï¼Œã€Œå­¸è™Ÿã€è¢«é¸ç‚º Primary Keyï¼Œé‚£ã€Œèº«åˆ†è­‰å­—è™Ÿã€å¦‚æœä¹Ÿèƒ½å”¯ä¸€ï¼Œå°±å±¬æ–¼ Alternate Keyã€‚

    Candidate Key å’Œ Alternate Key å…¶å¯¦æ˜¯ä¸€å€‹ã€ŒåŒ…å«ã€èˆ‡ã€Œè¢«å‰©ä¸‹ã€çš„é—œä¿‚ï¼š
    æ‰€æœ‰ Alternate Key éƒ½æ˜¯ Candidate Keyï¼Œ
    ä½†ä¸æ˜¯æ‰€æœ‰ Candidate Key éƒ½æœƒè®Šæˆ Alternate Keyï¼Œå› ç‚ºå…¶ä¸­æœ‰ä¸€å€‹è¢«é¸å»ç•¶ Primary Key äº†ã€‚

5. Composite Key (è¤‡åˆéµ)
    å®šç¾©ï¼š

    æŒ‡çš„æ˜¯ã€Œç”¨å…©å€‹æˆ–ä»¥ä¸Šçš„æ¬„ä½çµ„åˆåœ¨ä¸€èµ·ã€æ‰è¶³ä»¥æ§‹æˆã€Œå”¯ä¸€è­˜åˆ¥ã€çš„éµã€‚
    ç•¶å–®ä¸€æ¬„ä½ç„¡æ³•ä¿è­‰å”¯ä¸€ï¼Œä½†å¤šå€‹æ¬„ä½åˆèµ·ä¾†å°±èƒ½å”¯ä¸€ï¼Œé€™çµ„åˆå°±å«åš Composite Keyã€‚
    ä¾‹å­ï¼š

    åœ¨ã€Œé¸èª²ã€(Enrollment) è¡¨è£¡é¢ï¼Œå¯èƒ½æœ‰ï¼ˆå­¸ç”ŸIDã€èª²ç¨‹IDï¼‰ä¸€èµ·åšä¸»éµï¼Œå–®ç¨ã€Œå­¸ç”ŸIDã€æˆ–ã€Œèª²ç¨‹IDã€éƒ½ä¸å”¯ä¸€ï¼Œä½†æ˜¯åˆèµ·ä¾†å°±èƒ½å”¯ä¸€è­˜åˆ¥ä¸€ç­†ã€Œé€™ä½å­¸ç”Ÿé¸äº†å“ªå ‚èª²ã€çš„ç´€éŒ„ã€‚
    åœ¨å¤šå°å¤šé—œä¿‚çš„ã€Œé—œè¯è¡¨ã€(Junction Table) ä¸­å¾ˆå¸¸è¦‹ã€‚

6. Foreign Keyï¼ˆå¤–éµï¼‰
    å®šç¾©ï¼š

    åœ¨ä¸€å¼µè¡¨è£¡é¢ï¼Œç”¨ä¾†åƒç…§(Refernce)å¦ä¸€å¼µè¡¨ä¸»éµ(æˆ–å”¯ä¸€çš„ Candidate Key)çš„æ¬„ä½(æˆ–æ¬„ä½çµ„åˆ)ã€‚
    å¤–éµæœƒã€Œé€£åˆ°ã€å¦ä¸€å¼µè¡¨çš„ã€ŒPrimary Key æˆ– Candidate Keyã€ï¼Œç”¨ä¾†è¡¨æ˜å…©å¼µè¡¨ä¹‹é–“çš„é—œä¿‚(ä¸€å°å¤šã€å¤šå°å¤šç­‰)ã€‚
    ç‚ºä»€éº¼éœ€è¦ï¼š

    å¤–éµå¯ä»¥ä¿è­‰è³‡æ–™çš„ä¸€è‡´æ€§(Referential Integrity)ï¼Œå¦‚æœå¤–éµæŒ‡çš„é‚£ç­†è¨˜éŒ„åœ¨çˆ¶è¡¨(Parent Table)ä¸å­˜åœ¨ï¼Œå°±ä¸èƒ½æ–°å¢é€™ç­†è³‡æ–™ï¼Œæˆ–æ˜¯å¦‚æœçˆ¶è¡¨åˆªé™¤/æ›´æ–°äº†é‚£ç­†è³‡æ–™ï¼Œä¹Ÿæœƒå½±éŸ¿æˆ–é™åˆ¶å¤–éµè¡¨ä¸­çš„è³‡æ–™ã€‚
    ä¾‹å­ï¼š

    åœ¨ã€Œè¨‚å–®æ˜ç´°ã€è¡¨ä¸­ï¼ŒCustomerID å¯èƒ½æ˜¯æŒ‡å‘ã€Œé¡§å®¢ã€è¡¨(çˆ¶è¡¨)çš„ CustomerID (PK)ï¼›
    åœ¨ã€Œé¸èª²ã€è¡¨ä¸­ï¼Œå­¸ç”ŸID å’Œ èª²ç¨‹ID éƒ½æœƒæ˜¯å¤–éµï¼Œåˆ†åˆ¥é€£åˆ°ã€Œå­¸ç”Ÿã€è¡¨å’Œã€Œèª²ç¨‹ã€è¡¨çš„ä¸»éµã€‚
--------------------------------------------------------------------------------------------

normal func
agg func
window func

-- CTE (Common Table Expressions) é€šç”¨è³‡æ–™è¡¨é‹ç®—å¼ --> with tmp as (sub_query)

agg func --> NULL WON'T be included, but count will (count(*))
primary: unique + non-null
NULL ä¸æœƒåƒèˆ‡æ¯”è¼ƒ a > 10, if a has any null values --> these won't be select or oped.
NULL è¡¨ç¤ºçš„æ˜¯ä»€éº¼éƒ½æ²’æœ‰ï¼Œå®ƒèˆ‡ç©ºå­—ä¸² ('')ã€æ•¸å­— 0 ä¸¦ä¸ç­‰åƒ¹ï¼Œä¸”ä¸èƒ½ç”¨æ–¼æ¯”è¼ƒï¼
ä¾‹å¦‚ï¼š<expr> = NULL æˆ– NULL = '' çš„çµæœç‚º FALSEã€‚
è¦åˆ¤æ–· NULLï¼Œå¿…é ˆä½¿ç”¨ IS NULL æˆ– IS NOT NULL ä¾†é€²è¡Œæª¢æŸ¥ã€‚

comparison with null value it won't give true or false values
bonus IS NULL é€™å€‹æ¢ä»¶æ˜¯ å¿…è¦çš„ï¼Œ
å› ç‚ºåœ¨ SQL ä¸­ï¼ŒNULL ä¸æ˜¯æ•¸å­—ï¼Œä¹Ÿä¸èƒ½ç”¨ä¾†æ¯”è¼ƒå¤§å°ï¼Œæ‰€ä»¥ b.bonus < 1000 ä¸æœƒåŒ…å« NULL å€¼ã€‚

self join --> need on (emp vs mgr)
cross join --> A rows * B rows (different table)
full (outer) join -> all rows, no matter matched or not.

INSERT INTO --> need both tables exist
SELECT INTO --> create a new table from the existing one

rank: 1 1 3
dense_rank: 1 1 2 2 3
row_number: 1 2 3 4 
over (partition something orderby another)
--> rank, dense_rank, row_number, range, lead, lag
diff: with groupby --> groupby reduce the #of cols while over-partition keeps
over means do ops on a dataset
lag/lead æ˜¯offset row (default respect NULLs)

limit offset --> offset first then limit
e.g., limit 3 offset 2 --> first offset 2 rows, and choose the last three in a row. 

view -> virutual table --> select only -> update when querying 
materialized view (cache like) -> with real data -> need to update manually
store procedure (SP): sort of like function in SQL, can reduce IO/CPU workload
# IN(read), OUT(return the output), INOUT (best, bidirection)
Common Table Expression (CTE): temporary table (with temp_name as)

ACID
Atomic: all successful or all failed
Consistency: e.g., bank balance must >= 0
isolation: each transaction is independent from each other (e.g., prevent phantom read)
durability: store the data forever 

INDEX: B+ index (data distriubtion), é‡è¤‡è¶Šå°‘æ•ˆç‡è¶Šå¥½ é€Ÿåº¦è¶Šå¿« (balanced/non-balanced tree)
Partition (same table, e.g. hash partition)
Sharding (tables in different physical storage)
Clustering: store similar data in the neighboring physical address (e.g., disk)

âœ… æœ€ä½³å¯¦è¸
ğŸ”¹ ä½•æ™‚é©åˆåŠ ç´¢å¼•ï¼Ÿ
å”¯ä¸€å€¼è¼ƒå¤šï¼ˆé«˜é¸æ“‡æ€§ï¼‰ï¼Œå¦‚ id, emailã€‚
ç¶“å¸¸å‡ºç¾åœ¨ WHERE æ¢ä»¶ä¸­ä¸”èƒ½é¡¯è‘—éæ¿¾æ•¸æ“šï¼Œå¦‚ order_dateã€‚
ç¶“å¸¸ç”¨æ–¼ JOIN æˆ– GROUP BYï¼Œå¦‚ customer_idã€‚
ğŸ”¹ ä½•æ™‚ä¸é©åˆåŠ ç´¢å¼•ï¼Ÿ
å¤§é‡é‡è¤‡å€¼ï¼ˆä½é¸æ“‡æ€§ï¼‰ï¼Œå¦‚ gender, statusã€‚
è¡¨å¾ˆå°ï¼ˆ< 1000 è¡Œï¼‰ï¼Œå…¨è¡¨æƒææ›´å¿«ã€‚
é »ç¹ INSERT / UPDATEï¼Œå°è‡´ç´¢å¼•ç¶­è­·æˆæœ¬é«˜ã€‚



DELETEï¼šåˆªé™¤ç‰¹å®šè¨˜éŒ„ï¼ˆå¯å›æ»¾ï¼‰
ğŸ“Œ é€è¡Œåˆªé™¤è¡¨ä¸­çš„è³‡æ–™ï¼Œå¯ä»¥åŠ  WHERE æ¢ä»¶
ğŸ“Œ å¯å›æ»¾ (ROLLBACK)ï¼Œå› ç‚ºæœƒè¨˜éŒ„åˆ° UNDO LOG
ğŸ“Œ æœƒè§¸ç™¼ DELETE è§¸ç™¼å™¨ (Trigger)
ğŸ“Œ åŸ·è¡Œé€Ÿåº¦è¼ƒæ…¢ï¼Œå› ç‚ºå®ƒéœ€è¦è¨˜éŒ„æ¯ä¸€è¡Œçš„åˆªé™¤

TRUNCATEï¼šæ¸…ç©ºè¡¨ï¼ˆä¸å¯å›æ»¾ï¼‰
ğŸ“Œ åˆªé™¤æ•´å€‹è¡¨çš„æ‰€æœ‰è³‡æ–™ï¼Œä½†ä¸åˆªè¡¨çµæ§‹
ğŸ“Œ ä¸å¯å›æ»¾ (ROLLBACK)ï¼Œå› ç‚ºä¸æœƒè¨˜éŒ„ UNDO LOG
ğŸ“Œ ä¸æœƒè§¸ç™¼ DELETE è§¸ç™¼å™¨
ğŸ“Œ åŸ·è¡Œé€Ÿåº¦æ¯” DELETE å¿«ï¼Œå› ç‚ºå®ƒç›´æ¥æ¸…ç©ºè¡¨

DROPï¼šåˆªé™¤è¡¨
ğŸ“Œ åˆªé™¤æ•´å€‹è¡¨ï¼ŒåŒ…æ‹¬çµæ§‹ã€ç´¢å¼•ã€ç´„æŸ
ğŸ“Œ ä¸å¯å›æ»¾ (ROLLBACK)ï¼Œå› ç‚ºæœƒç›´æ¥åˆªé™¤è¡¨
ğŸ“Œ åˆªé™¤å¾Œï¼Œè¡¨ç„¡æ³•æ¢å¾©ï¼Œéœ€è¦é‡æ–° CREATE TABLE
ğŸ“Œ åŸ·è¡Œé€Ÿåº¦æœ€å¿«

indexçš„é¡åˆ¥åˆ†ç‚º B-tree èˆ‡ Hash 2 ç¨®ï¼Œé€™ 2 ç¨®æœ‰å„è‡ªé©åˆçš„æƒ…å¢ƒï¼Œè­¬å¦‚æŸäº›ä¸é‡è¤‡çš„æ¬„ä½ï¼Œå°±é©åˆä½¿ç”¨ Hash ä½œç‚ºç´¢å¼•ï¼Œä¸é Hash ç´¢å¼•ç„¡æ³•é€²è¡Œç¯„åœæŸ¥è©¢å’Œæ’åºï¼Œå› æ­¤è¦è€ƒæ…®æ¸…æ¥š
partition: same table's order (hash, range ....)
clustering: physical storage order (i.e. disk)


SELECT * 
FROM Delivery 
WHERE (customer_id, order_date) IN (
    (1, '2024-01-01'),
    (2, '2024-01-02'),
    (3, '2024-01-03')
);
é€™è£¡çš„ IN ä½œç”¨æ–¼å¤šå€‹æ¬„ä½ï¼ŒæœƒåŒ¹é… (customer_id, order_date) æ˜¯å¦èˆ‡æä¾›çš„æ•¸çµ„ï¼ˆtuplesï¼‰ç›¸ç¬¦ã€‚


æ¨™æº– SQL ä¸­ï¼Œç•¶ä½ åœ¨ GROUP BY æŸäº›æ¬„ä½ï¼ˆå¯ä»¥æ˜¯ä¸€å€‹æˆ–å¤šå€‹ã€Œéµã€ï¼‰æ™‚ï¼ŒSELECT å­å¥è£¡ åªèƒ½å‡ºç¾ï¼š
èˆ‡ GROUP BY æ¢ä»¶ä¸­ä¸€æ¨¡ä¸€æ¨£çš„æ¬„ä½ï¼ˆæˆ–åŒç­‰æ–¼é€™äº›æ¬„ä½çš„è¡¨é”å¼ï¼‰ï¼Œä»¥åŠ
èšåˆå‡½æ•¸ï¼ˆSUM, COUNT, MIN, MAX, AVG...ï¼‰çš„çµæœã€‚
ä»»ä½•ã€Œæ²’æœ‰åœ¨ GROUP BY å‡ºç¾ã€ä¹Ÿæ²’æœ‰è¢«èšåˆã€çš„æ¬„ä½ï¼Œéƒ½æœƒå¼•ç™¼ SQL éŒ¯èª¤ï¼ˆç”¢ç”Ÿä¸ç¢ºå®šçš„çµæœï¼‰ã€‚
select g_col, max(a), min(b) --> OK
select g_col, max(a) --> OK
select g_col, max(a), c --> WRONG
# select g_col_1, g_col_2, MIN(price) AS min_price,, MAX(price) AS max_price -> OK
from table
group by g_col
# group by g_col_1, g_col_2 -> OK (ref #)
# You can put expression in the sum e.g., sum(price > 0)
select g_col --> (OK)
group by g_col


<çª—å£å‡½æ•¸> OVER (
    PARTITION BY <åˆ†çµ„æ¬„ä½>
    ORDER BY <æ’åºæ¬„ä½>
    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
)
ğŸ”¹ ROWS BETWEEN çš„å®šç¾©
6 PRECEDINGï¼šè¡¨ç¤ºç•¶å‰è¡Œå¾€ä¸Šæ•¸ 6 è¡Œï¼ˆåŒ…å«é€™ 6 è¡Œï¼‰ã€‚
CURRENT ROWï¼šè¡¨ç¤ºç•¶å‰è¡Œã€‚
é€™æ¨£çš„ç¯„åœå°±æ˜¯ã€Œç•¶å‰è¡Œ + å‰ 6 è¡Œã€ï¼Œå…± 7 è¡Œã€‚

ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW	å¾ç¬¬ä¸€è¡Œåˆ°ç•¶å‰è¡Œçš„ç´¯ç©è¨ˆç®—ï¼ˆç´¯ç©ç¸½å’Œï¼‰ã€‚
ROWS BETWEEN 6 PRECEDING AND CURRENT ROW	  è¨ˆç®—ç•¶å‰è¡Œ + å‰ 6 è¡Œï¼ˆç§»å‹•å¹³å‡ï¼‰ã€‚
ROWS BETWEEN CURRENT ROW AND 6 FOLLOWING	è¨ˆç®—ç•¶å‰è¡Œ + å¾Œ 6 è¡Œï¼ˆæœªä¾† 7 å¤©å¹³å‡ï¼‰ã€‚
ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING	è¨ˆç®—æ•´å€‹è¡¨çš„èšåˆå€¼ï¼ˆå¦‚ AVG() è¨ˆç®—å…¨è¡¨å¹³å‡ï¼‰ã€‚

Coalesce: return first non-null value; if all are nulls, then return ull



"
--197. Rising Temperature
-- select w1.id from weather w1, weather w2 --> return all combs n^2 <- self-join
-- By doing a self-join on the Weather table, we create a Cartesian product of the table with itself, creating pairs of days
-- Postgresql
select w1.id from weather w1, weather w2
where w1.temperature > w2.temperature
and w1.recordDate::date - w2.recordDate::date = 1

-- MYSQL - 1
WITH PreviousWeatherData AS
(
    SELECT 
        id,
        recordDate,
        temperature, 
        LAG(temperature, 1) OVER (ORDER BY recordDate) AS PreviousTemperature,
        LAG(recordDate, 1) OVER (ORDER BY recordDate) AS PreviousRecordDate
    FROM 
        Weather
)
SELECT 
    id 
FROM 
    PreviousWeatherData
WHERE 
    temperature > PreviousTemperature
AND 
recordDate = DATE_ADD(PreviousRecordDate, INTERVAL 1 DAY);
-- and DATEDIFF(recordDate, previousRecordDate) = 1

-- MySQL - 2
SELECT w1.id FROM Weather w1
JOIN Weather w2
ON DATEDIFF(w1.recordDate, w2.recordDate) = 1
WHERE w1.temperature > w2.temperature


-- 1661. Average Time of Process per Machine
SELECT 
    machine_id,
    ROUND(SUM(CASE 
                  WHEN activity_type = 'start' THEN -timestamp 
                  ELSE timestamp 
              END) * 1.0
          / COUNT(DISTINCT process_id), 3) AS processing_time
FROM 
    Activity
GROUP BY 
    machine_id;


-- 620. Not Boring Movies
select * from Cinema
where id % 2 = 1 
and description <> "boring"
order by rating des

-- 1978. Employees Whose Manager Left the Company
-- manager is also an employee 
select employee_id from Employees
where salary < 30000
and manager_id NOT IN (select employee_id from Employees)
order by employee_id


-- 1303. Find the Team Size
-- using window function
select employee_id, count(team_id) over (partition by team_id) as team_size 
from Employee


-- 2356. Number of Unique Subjects Taught by Each Teacher
select teacher_id, count(distinct subject_id) as cnt from Teacher
group by teacher_id


-- 2989. Class Performance
with tmp as (
    select (assignment1 + assignment2 + assignment3) as total_score
    from Scores
)
select (max(total_score) - min(total_score)) as difference_in_score from tmp


-- 3338. Second Highest Salary II
with tmp as (
    select emp_id, dept, dense_rank() over (partition by dept order by salary desc) as rnk 
    from employees
)
select emp_id, dept from tmp
where rnk = 2
order by emp_id


-- 2339. All the Matches of the League
select t1.team_name as home_team, t2.team_name as away_team
from Teams as t1
cross join Teams as t2
where (on) t1.team_name != t2.team_name


-- 2985. Calculate Compressed Mean
select round(sum(item_count * order_occurrences) / sum(order_occurrences), 2) as average_items_per_order
from Orders 


-- 1571. Warehouse Manager
with tmp as (
    select product_id, (Width*Length*Height) as volume
    from Products
)
select w.name as warehouse_name, sum(p.volume * w.units) as volume
from Warehouse as w
inner join tmp as p
on w.product_id = p.product_id
group by w.name


-- 2084. Drop Type 1 Orders for Customers With Type 0 Orders
select order_id, customer_id, order_type 
from Orders
where order_type = 0
or (order_type = 1 and customer_id not in (select customer_id from orders where order_type = 0))


-- 3150. Invalid Tweets II
select tweet_id from Tweets
where length(content) > 140
or length(content) - length(replace(content, "#", '')) > 3 
or length(content) - length(replace(content, "@", '')) > 3 


-- 1308. Running Total for Different Genders
-- running total
-- sum over --> running total
select gender, day,
sum(score_points) over(partition by gender order by day) as total
from Scores


-- 1445. Apples & Oranges
-- solved
select sale_date, SUM(CASE WHEN fruit = 'apples' THEN sold_num ELSE -sold_num END) as diff
from Sales
group by sale_date


-- 1795. Rearrange Products Table
-- pivot using union 

Products table:
+------------+--------+--------+--------+
| product_id | store1 | store2 | store3 |
+------------+--------+--------+--------+
| 0          | 95     | 100    | 105    |
| 1          | 70     | null   | 80     |
+------------+--------+--------+--------+
Output: 
+------------+--------+-------+
| product_id | store  | price |
+------------+--------+-------+
| 0          | store1 | 95    |
| 0          | store2 | 100   |
| 0          | store3 | 105   |
| 1          | store1 | 70    |
| 1          | store3 | 80    |
+------------+--------+-------+
select product_id, 'store1' as store, store1 as price
from products
where store1 is not NULL
union
select product_id, 'store2' as store, store2 as price
from products
where store2 is not NULL
union
select product_id, 'store3' as store, store3 as price
from products
where store3 is not NULL


-- 1853. Convert Date Format
SELECT DATE_FORMAT(day, "%W, %M %e, %Y") AS day FROM Days;


-- 1393. Capital Gain/Loss
select stock_name, sum(CASE WHEN operation = 'Buy' THEN -price ELSE price END) as capital_gain_loss


-- 1581. Customer Who Visited but Did Not Make Any Transactions
select v.customer_id, sum(CASE WHEN t.transaction_id is NULL THEN 1 ELSE 0 END) as count_no_trans 
from Visits as v
left join Transactions as t
on v.visit_id = t.visit_id
group by v.customer_id
having count_no_trans > 0


-- 1280. Students and Examinations
-- https://www.fooish.com/sql/cross-join.html
WITH StudentSubjects AS (
    -- 1. ç”¢ç”Ÿæ‰€æœ‰å­¸ç”Ÿ Ã— æ‰€æœ‰ç§‘ç›®
    SELECT s.student_id, s.student_name, sub.subject_name
    FROM Students s
    CROSS JOIN Subjects sub
)

SELECT 
    ss.student_id,
    ss.student_name,
    ss.subject_name,
    COUNT(e.subject_name) AS attended_exams
-- count (e.) is critical, e has NULL, but ss does not
FROM StudentSubjects ss
LEFT JOIN Examinations e 
ON ss.student_id = e.student_id 
AND ss.subject_name = e.subject_name
GROUP BY ss.student_id, ss.student_name, ss.subject_name
ORDER BY ss.student_id, ss.subject_name;

-- better solution
-- two CTEs
with all_stu_sub as (
    select * from Students
    cross join Subjects
),

exam_grp as (
    select student_id, subject_name, COUNT(*) as 'attended_exams' from Examinations
    group by student_id, subject_name
)

select a.student_id, a.student_name, a.subject_name, COALESCE(e.attended_exams, 0) as 'attended_exams'
from all_stu_sub as a
left join exam_grp as e
on a.student_id = e.student_id
and a.subject_name = e.subject_name
order by a.student_id, a.subject_nam


-- 1934. Confirmation Rate
with tmp as (
    select s.user_id, c.action from Signups as s
    left join Confirmations as c
    on s.user_id = c.user_id
)

SELECT 
    user_id, 
    ROUND(
        SUM(CASE WHEN action = 'confirmed' THEN 1 ELSE 0 END) * 1.0 / COUNT(*), 
        2
    ) AS confirmation_rate 
FROM tmp 
GROUP BY user_id;


-- 1251. Average Selling Price
select p.product_id, COALESCE(ROUND(SUM(p.price * u.units) / SUM(u.units), 2), 0) as average_price
from Prices as p
left join UnitsSold as u
on p.product_id = u.product_id
and purchase_date between start_date and end_date 
group by p.product_id


-- 1075. Project Employees I
select p.project_id, ROUND(AVG(e.experience_years), 2) as average_years
from Project as p
left join Employee as e
on p.employee_id = e.employee_id
group by p.project_id


-- 1633. Percentage of Users Attended a Contest
with tmp as (
    select count(*) as total_number from users
)
select r.contest_id, ROUND((count(u.user_id) *100 / (select total_number from tmp)), 2) as percentage from Users as u
inner join Register as r
on u.user_id = r.user_id
group by r.contest_id
order by percentage desc,  r.contest_id as


-- 1211. Queries Quality and Percentage
-- remember casting --> mutiply by .0
-- the use of avg
-- poor quality probably need coalesce for 0
select query_name,
round(avg(rating*1.0 / position), 2) as quality,
round(sum(case when rating < 3 then 1 else 0 end) * 100.0 / count(query_name), 2) as poor_query_percentage
from Queries
group by query_name

--  1193. Monthly Transactions I
SELECT DATE_FORMAT(trans_date, '%Y-%m') AS month, country,
COUNT(state) as trans_count,
SUM(CASE WHEN state = 'approved' THEN 1 ELSE 0 END) as approved_count,
SUM(amount) as trans_total_amount,
SUM(CASE WHEN state = 'approved' THEN amount ELSE 0 END) as approved_total_amount 
from Transactions
group by month, country


-- 1174. Immediate Food Delivery II
with tmp1 as (
    select customer_id, order_date, dense_rank() over (partition by customer_id order by order_date) as rnk
    from Delivery
),
tmp2 as (
    select d.customer_id, d.order_date, (CASE WHEN d.order_date = d.customer_pref_delivery_date THEN 'immediate' ELSE 'scheduled' END) as type 
    from Delivery as d
    inner join tmp1 as t
    on t.customer_id = d.customer_id
    and t.order_date = d.order_date
    where rnk = 1
)
select ROUND(AVG(type = 'immediate') * 100.0, 2) as immediate_percentage from tmp2

-- 1174. Immediate Food Delivery II
SELECT 
    ROUND(AVG(order_date = customer_pref_delivery_date) * 100.0, 2) AS immediate_percentage
FROM Delivery
WHERE (customer_id, order_date) IN (
    SELECT customer_id, MIN(order_date) AS first_order_date
    FROM Delivery
    GROUP BY customer_id
)


-- 550. Game Play Analysis IV
-- read the problem statement properly
WITH first_login_cte AS (
    -- æ¯ä½ç©å®¶çš„ã€Œç¬¬ä¸€æ¬¡ç™»å…¥ã€æ—¥æœŸ
    SELECT 
        player_id, 
        MIN(event_date) AS first_login
    FROM Activity
    GROUP BY player_id
),
logged_again_cte AS (
    -- åªçœ‹ã€Œé¦–ç™»æ—¥ + 1 å¤©ã€æ˜¯å¦æœ‰ç™»å…¥
    SELECT DISTINCT f.player_id
    FROM first_login_cte f
    INNER JOIN Activity a
        ON a.player_id = f.player_id
       AND DATEDIFF(a.event_date, f.first_login) = 1
)
SELECT 
    ROUND(
        COUNT(DISTINCT lac.player_id) *1.0
        / (SELECT COUNT(DISTINCT player_id) FROM Activity)
    , 2
    ) AS fraction
FROM logged_again_cte as lac


-- 1141. User Activity for the Past 30 Days I
-- INTERVAL 29 DAY --> D-30
-- INTERVAL N DAY --> D-(N+1)
select activity_date as "day", count(distinct user_id) as active_users
from Activity
group by activity_date
having activity_date between DATE_SUB("2019-07-27", INTERVAL 29 DAY) and "2019-07-27"


-- 1070. Product Sales Analysis III
-- agg func, one main col and an agg col
-- (a, b) in subquery
with tmp as (
    select product_id, min(year) as first_year
    from Sales
    group by product_id
)
select product_id, year as first_year, quantity, price
from Sales
where (product_id, year) in (select * from tmp)


-- 1045. Customers Who Bought All Products
-- read the problem properly (pk and fk)
select customer_id
from Customer
group by customer_id
having count(distinct product_key) = (select count(*) from Product)


-- 610. Triangle Judgement
select x, y, z, (CASE WHEN x + y > z and y + z > x and x + z > y THEN "Yes" ELSE "No" END) as "triangle"
from Triangle

-- 610. Triangle Judgement
select x, y, z, if (x + y > z and y + z > x and x + z > y, "Yes", "No") as 'triangle'
from triangle


-- 1789. Primary Department for Each Employee
-- subquery
-- first select 'N' with only one row
-- and finally selecet "Y"
with tmp as (
    select employee_id, COUNT(distinct department_id) as cnt
    from Employee
    group by employee_id
    having cnt = 1
)
select employee_id, department_id
from Employee
where primary_flag = "Y"
or employee_id in (select employee_id from tmp)


-- 1731. The Number of Employees Which Report to Each Employee
-- every employee could be a mgr of any other
with mgr as (
    select employee_id, name from Employees
)
select m.employee_id, m.name, 
count(e.reports_to) as reports_count, 
ROUND(avg(e.age)) as average_age
from mgr as m
inner join Employees as e
on m.employee_id = e.reports_to
group by m.employee_id, m.name
order by employee_id


-- 626. Exchange Seats
-- a smart way to swap 
select (CASE WHEN id % 2 = 0 THEN id -1 
             WHEN id % 2 = 1 and id < (select count(*) from Seat) THEN id + 1
             ELSE id END) as `id` -- edge case
             , student from Seat
order by `id`


-- 180. Consecutive Numbers
with tmp as (
    select num, lag(num) over (order by id) as prev, lead(num) over (order by id) as next
    from Logs
)
select distinct num as ConsecutiveNums from tmp
where num = prev and num = nex


-- 1667. Fix Names in a Table
-- substr (str, pos, len)
-- start from 1 (inclusive) and proceed 1, so which is itself
-- 2, None --> start from 2 (inclusive) til the end
select user_id, CONCAT(upper(substr(name, 1, 1)), lower(substr(name, 2))) as name from Users
order by user_id


-- 1327. List the Products Ordered in a Period
select p.product_name, SUM(o.unit) as `unit`
from Products as p
inner join Orders as o
on p.product_id = o.product_id
where DATE_FORMAT(order_date, '%Y-%m') = '2020-02'
-- where left(order_date, 7) = '2020-02
group by p.product_id
having `unit` >= 10


-- 196. Delete Duplicate Emails
-- åœ¨è¨±å¤šè³‡æ–™åº«ç³»çµ±ï¼ˆç‰¹åˆ¥æ˜¯ MySQLï¼‰ä¸­ï¼Œå¦‚æœä½ åœ¨ä¸€å€‹ DELETEï¼ˆæˆ– UPDATEï¼‰æŒ‡ä»¤è£¡ï¼ŒåŒæ™‚åˆæƒ³å¾ã€ŒåŒä¸€å¼µè¡¨ã€é€²è¡Œ SELECT ä»¥å–å¾—æ¢ä»¶ï¼Œå¾€å¾€æœƒé‡åˆ°ä»¥ä¸‹éŒ¯èª¤æˆ–é™åˆ¶ï¼š
-- You can't specify target table 'XXX' for update in FROM clause
-- ä¹Ÿå°±æ˜¯èªªï¼Œä¸å…è¨±ç›´æ¥åœ¨ DELETE FROM Person çš„åŒæ™‚ï¼Œåœ¨ WHERE å­å¥çš„å­æŸ¥è©¢ä¸­ç›´æ¥ SELECT FROM Person åšèšåˆæˆ–éæ¿¾ã€‚

DELETE from Person
where id NOT IN (
    select ID from (
        select min(id) as ID from Person
        group by email
    ) t
)


-- 176. Second Highest Salary
-- SELECT (sub_query) AS 'secondHighestsalary' 
SELECT COALESCE(
    (SELECT DISTINCT salary 
     FROM (
         SELECT salary, DENSE_RANK() OVER (ORDER BY salary DESC) AS rnk
         FROM Employee
     ) t
     WHERE rnk = 2),
    NULL
) AS `SecondHighestSalary`


-- 185. Department Top Three Salaries
-- CTE (Common Table Expressions) é€šç”¨è³‡æ–™è¡¨é‹ç®—å¼
with tmp as (
    select d.name as Department, e.name as Employee, Salary, 
    dense_rank() over (partition by d.name order by e.salary desc) as rnk
    from Employee as e
    inner join Department as d
    on e.departmentId = d.id
)
select Department, Employee, Salary from tmp
where rnk <= 3


-- 1517. Find Users With Valid E-Mails
SELECT user_id, name, mail
FROM Users
-- Note that we also escaped the `@` character, as it has a special meaning in some regex flavors
WHERE mail REGEXP '^[a-zA-Z][a-zA-Z0-9_.-]*\\@leetcode\\.com$'


-- 1907. Count Salary Categories
-- SUM is critical here, since we need to take care of 0
-- The combination of Union and CASE
select "Low Salary" as category,
    SUM(CASE WHEN income < 20000 THEN 1 ELSE 0 END) as accounts_count
from accounts
union
select "Average Salary" as category,
    SUM(CASE WHEN income >= 20000 and income <= 50000 THEN 1 ELSE 0 END) as accounts_count
from accounts
union
select "High Salary" as category,
    SUM(CASE WHEN income > 50000 THEN 1 ELSE 0 END) as accounts_count
from account


-- 1484. Group Sold Products By The Date
-- very special, not that useful
select sell_date, count(distinct product) as num_sold, 
group_concat(distinct product order by product SEPARATOR ',') as products
from Activities
group by sell_date
order by sell_dat


-- 1204. Last Person to Fit in the Bus
select person_name from (
    select person_name, SUM(weight) over (order by turn) as total_weight
    from Queue
) t
where total_weight <= 1000
order by total_weight desc
limit 1


-- 1164. Product Price at a Given Date
WITH
  cte_price AS (
    SELECT
      product_id,
      new_price,
      ROW_NUMBER() OVER (PARTITION BY product_id ORDER BY change_date DESC) AS rn
    FROM
      Products
    WHERE
      change_date <= '2019-08-16'
  )

SELECT
  DISTINCT Products.product_id,
  COALESCE(price.new_price, 10) AS price
FROM
  Products
LEFT JOIN
  cte_price AS price
ON
  Products.product_id = price.product_id
  AND price.rn = 1



CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT
BEGIN
DECLARE M INT; 
    SET M = N-1; 
  RETURN (
      SELECT DISTINCT salary
      FROM Employee
      ORDER BY salary DESC
      LIMIT M, 1  -- index (rowcount-1), start from M+1=N, choose 1
      -- 0-indexed
      -- LIMIT offset, row_count
      -- 3 â†’ åç§»é‡ï¼ˆoffset)
      -- 1 â†’ å›å‚³ 1 è¡Œ

      -- LIMIT row_count OFFSET offset
      -- 3 â†’ å›å‚³ 3 è¡Œ
      -- OFFSET 1 â†’ è·³éå‰ 1 è¡Œ

  );
END 


-- 2990. Loan Types
SELECT user_id 
FROM Loans
WHERE loan_type IN ('Refinance', 'Mortgage')
GROUP BY user_id
HAVING COUNT(DISTINCT loan_type) = 2
ORDER BY user_id as


-- 2987. Find Expensive Cities
select city from Listings
group by city
having avg(price) >  (select avg(price) from Listings)
order by cit


-- 181. Employees Earning More Than Their Managers
select e1.name as 'Employee'
from Employee e1
inner join Employee e2
on e1.managerId = e2.Id
where e1.salary > e2.salary


-- 586. Customer Placing the Largest Number of Orders
select customer_number
from Orders
group by customer_number
having count(order_number) = (
    SELECT count(order_number)
	FROM orders
	GROUP BY customer_number
	ORDER BY count(order_number) DESC LIMIT 1
)